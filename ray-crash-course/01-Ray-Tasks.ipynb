{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Crash Course - Tasks\n",
    "\n",
    "Â© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../images/AnyscaleAcademyLogo.png)\n",
    "\n",
    "Let's quickly explore the Ray API using some examples that demonstrate how Ray enables horizontal scalability.\n",
    "\n",
    "> **Tip:** For more about Ray, see [ray.io](https://ray.io) or the [Ray documentation](https://docs.ray.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the next _three_ notebook cells (shift+return, if you're new to notebooks), down to and including `run_simulations(...)`, and watch what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_lesson_util import make_dmaps, run_simulations, stop_simulations\n",
    "from pi_calc import str_large_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [1000, 10000, 100000]\n",
    "\n",
    "dmaps = make_dmaps(Ns)\n",
    "\n",
    "dmaps[0] + dmaps[1] + dmaps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulations(dmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP: If you want to stop them, uncomment and run the next line:\n",
    "# stop_simulations(dmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../images/Pi-estimates.png) for a screen grab.)\n",
    "\n",
    "What we just did was estimate $\\pi$ (~3.14159) using a [_Monte Carlo_ technique](https://en.wikipedia.org/wiki/Monte_Carlo_method), where we randomly sampled a _uniform distribution_, one with equal probably of picking any point in a square.\n",
    "\n",
    "It works like this. Imagine each blue square is a piece of paper 2 meters by 2 meters you put on a wall. The circle inside each one has radius 1 meter.\n",
    "\n",
    "Now suppose you throw $N$ darts at each paper. We're seeing $N = {\\sim}1000, {\\sim}10000, {\\sim}100000$ examples. (This will be hard on your wall, so don't try this at home...)\n",
    "\n",
    "Some darts will land inside the circle, call them $n$, and the rest will land outside, $N-n$. The area of a circle is ${\\pi}r^{2}$ and the area of a square is $(2r)^{2} = 4r^{2}$. The ratio of $n/N$ _approximately_ equals the ratio of the circle area over the square area, ${\\pi}r^{2}/4r^{2} = {\\pi}/4$. (Does it make sense that this ratio is independent of the actual radius value?).\n",
    "\n",
    "In other words,\n",
    "\n",
    "$\\pi/4 \\approx n/N$\n",
    "\n",
    "$\\pi \\approx 4n/N$\n",
    "\n",
    "So, to approximate $\\pi$, we can count the number of darts thrown and the number that land inside the circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably noticed three things while the simulations were running or after they finished:\n",
    "\n",
    "1. The accuracy improved for larger $N$... well usually. Sometimes a lower $N$ simulation gets \"lucky\" and does as well as a higher $N$. In a real experiment, we would do many runs and then compute the average and standard deviation. (We'll do that below.)\n",
    "2. Because each $N$ is 10 times the $N$ to the left, it took roughly 10 times as long for the second to finish compared to the first, etc.\n",
    "3. The updates in the second and third simulations appeared to go faster as the neighbors to the left finished.\n",
    "\n",
    "What this means is that if we really want a good estimate of $\\pi$, we have to do runs with large $N$, but then we wait longer. Ideally, to get fast _and_ accurate results, we would do as much work as possible in parallel, leveraging all the CPU cores available on our machine ... or our cluster. \n",
    "\n",
    "Let's use [_Ray_](https://ray.io) to achieve this.\n",
    "\n",
    "> **Note:** There is a lot of Python code used in this notebook, both for calculating Pi and for the graphs. We won't show most of it, but all the code can be found in this directory, `pi_calc.py` (calculating $\\pi$) and `task_lesson_util.py` (graphics). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelism with Ray\n",
    "\n",
    "We did the previous calculation without fully exploiting all available cores. In a cluster, the rest of the cores _on the rest of the machines_ would be idle, too.\n",
    "\n",
    "We can use Ray to parallelize a lot of this work. Let's see how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, statistics, time\n",
    "import ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some constants we'll use (and explain) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "trials = 20  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Start Ray\n",
    "\n",
    "If you are running these tutorials on your laptop, each notebook will start a mini-cluster when we call `ray.init()` below. They we'll shut it down at the end of the notebook, so be sure to evaluate the last cell in each notebook that calls `ray.shutdown()`.\n",
    "\n",
    "If you are learning on the Anyscale platform, your environment is already running a Ray cluster with one or more nodes. So, when we call `ray.init()`, it will connect to that running cluster. You should still run the `ray.shutdown()` cell at the end of each notebook, but it won't shutdown the whole cluster.\n",
    "\n",
    "For more details on the options you can pass to `ray.init()`, see lesson 6, [Exploring Ray API Calls](06-Exploring-Ray-API-Calls.ipynb). \n",
    "If you are interested in the details of running a Ray cluster using the `ray` CLI, see lesson 7, [Running Ray Clusters](07-Running-Ray-Clusters.ipynb) and see also the corresponding [Ray documentation](https://docs.ray.io/en/latest/starting-ray.html#using-ray-on-a-cluster). There is also a script `tools/start-ray.sh` that can you play with. (It was used in an earlier version of these tutorials.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ignore_reinit_error=True` argument tells Ray not to complain if we rerun the cell; Ray will just ignore the request to initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip:** Having trouble starting Ray? See the [Troubleshooting](../reference/Troubleshooting-Tips-Tricks.ipynb) tips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we don't need it immediately, we'll use the Ray Dashboard to watch performance metrics like CPU utilization.\n",
    "\n",
    "The next cell prints the URL for the Ray Dashboard. **This is only correct if you are running this tutorial on a laptop.** Click the link to open the dashboard.\n",
    "\n",
    "If you are running on the Anyscale platform, use the URL provided by your instructor to open the Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dashboard URL: http://{ray.get_dashboard_url()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to do the Pi calculation that simplifies the code we used above for graphing purposes. We won't do the \"dart graphs\" from now on, because they add a lot of overhead that would obscure the performance\n",
    "\n",
    "This function estimates $\\pi$ for the number of samples requested. It uses [NumPy](https://docs.scipy.org/doc/numpy/index.html). If you're not familiar with it, the implementation details aren't essential to understand, but the comments try to explain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi(num_samples):\n",
    "    xs = np.random.uniform(low=-1.0, high=1.0, size=num_samples)   # Generate num_samples random samples for the x coordinate.\n",
    "    ys = np.random.uniform(low=-1.0, high=1.0, size=num_samples)   # Generate num_samples random samples for the y coordinate.\n",
    "    xys = np.stack((xs, ys), axis=-1)                              # Like Python's \"zip(a,b)\"; creates np.array([(x1,y1), (x2,y2), ...]).\n",
    "    inside = xs*xs + ys*ys <= 1.0                                  # Creates a predicate over all the array elements.\n",
    "    xys_inside = xys[inside]                                       # Selects only those \"zipped\" array elements inside the circle.\n",
    "    in_circle = xys_inside.shape[0]                                # Return the number of elements inside the circle.\n",
    "    approx_pi = 4.0*in_circle/num_samples                          # The Pi estimate.\n",
    "    return approx_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [10000, 50000, 100000, 500000, 1000000] #, 5000000, 10000000]  # Larger values take a long time on small VMs and machines!\n",
    "maxN = Ns[-1]\n",
    "maxN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '{:10.5f} seconds: pi ~ {:7.6f}, stddev = {:5.4f}, error = {:5.4f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_it(n, trials):\n",
    "    print('trials = {:3d}, N = {:s}: '.format(trials, str_large_n(n, padding=12)), end='')   # str_large_n imported above.\n",
    "    start = time.time()\n",
    "    pis = [estimate_pi(n) for _ in range(trials)]\n",
    "    approx_pi = statistics.mean(pis)\n",
    "    stdev = statistics.stdev(pis)\n",
    "    duration = time.time() - start\n",
    "    error = (100.0*abs(approx_pi-np.pi)/np.pi)\n",
    "    print(fmt.format(duration, approx_pi, stdev, error))   # str_large_n imported above.\n",
    "    return trials, n, duration, approx_pi, stdev, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will take many seconds to complete (depending on your setup). As soon as it starts, switch to the Ray Dashboard you opened above. Notice the total CPU and memory utilizations at the top while the cell runs. \n",
    "\n",
    "> **Tip:** If all the following trials finish in under a few seconds for the largest `n` value in `Ns` and the largest number of trials, consider changing `Ns` above to add larger values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ns = [try_it(n, trials) for n in Ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trials = [try_it(maxN, trials) for trials in range(5,20,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We'll graph the data below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CPU utilization never gets close to 100%. On a four-core machine, for example, the number will be about 25%. (The Ray process meters will stay at or near zero until later in this notebook.)\n",
    "\n",
    "So, this runs on one core, while the other cores are idle. Now we'll try with Ray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Python Functions to Ray Tasks\n",
    "\n",
    "You create a Ray _task_ by decorating a normal Python function with `@ray.remote`. These tasks will be scheduled across your Ray cluster (or your laptop CPU cores).\n",
    "\n",
    "> **Tip:** The [Ray Package Reference](https://ray.readthedocs.io/en/latest/package-ref.html) in the [Ray Docs](https://ray.readthedocs.io/en/latest/) is useful for exploring the API features we'll learn.\n",
    "\n",
    "Here is a Ray task for `estimate_pi`. All we need is a wrapper around the original function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_estimate_pi(num_samples):\n",
    "    return estimate_pi(num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it. To invoke a task, you use `function.remote(args)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_estimate_pi.remote(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this `ObjectRef`? A Ray task is an asynchronous computation. The `ObjectRef` returned is a _future_ that we use to retrieve the resulting value from the task when it completes. We use `ray.get(ref)` to get it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = ray_estimate_pi.remote(100)\n",
    "print(ray.get(ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work with lists of refs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [ray_estimate_pi.remote(n) for n in [100, 1000, 10000]]\n",
    "print(ray.get(refs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try our test run again with our Ray task. We'll need a new \"try it\" function, because of the different task invocation logic. This function doesn't need to be a Ray task, however, so no `@ray.remote` decorator is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_try_it(n, trials):\n",
    "    print('trials = {:3d}, N = {:s}: '.format(trials, str_large_n(n, padding=12)), end='')   # str_large_n imported above.\n",
    "    start = time.time()\n",
    "    refs = [ray_estimate_pi.remote(n) for _ in range(trials)]\n",
    "    pis = ray.get(refs)\n",
    "    approx_pi = statistics.mean(pis)\n",
    "    stdev = statistics.stdev(pis)\n",
    "    duration = time.time() - start\n",
    "    error = (100.0*abs(approx_pi-np.pi)/np.pi)\n",
    "    print(fmt.format(duration, approx_pi, stdev, error))   # str_large_n imported above.\n",
    "    return trials, n, duration, approx_pi, stdev, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_data_ns = [ray_try_it(n, trials) for n in Ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_data_trials = [ray_try_it(maxN, trials) for trials in range(5,20,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The durations should be shorter than the non-Ray numbers. Let's graph our results and see. It will be easier if we first convert the `*data_*` lists to NumPy arrays, so they are easier to slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data_ns         = np.array(data_ns)\n",
    "np_data_trials     = np.array(data_trials)\n",
    "np_ray_data_ns     = np.array(ray_data_ns)\n",
    "np_ray_data_trials = np.array(ray_data_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh_util import two_lines_plot, means_stddevs_plot  # Some plotting utilities in `./bokeh_util.py`.\n",
    "from bokeh.plotting import show, figure\n",
    "from bokeh.layouts import gridplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a linear plot of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_lines = two_lines_plot(\n",
    "    \"N vs. Execution Times (Smaller Is Better)\", 'N', 'Time', 'No Ray', 'Ray', \n",
    "    np_data_ns[:,1], np_data_ns[:,2], np_ray_data_ns[:,1], np_ray_data_ns[:,2],\n",
    "    x_axis_type='linear', y_axis_type='linear')\n",
    "show(two_lines, plot_width=800, plot_height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../images/Pi-Ns-vs-times-linear.png). Note that this image is from a run that included the larger values for `N` that are commented out in the definition of `Ns` above.)\n",
    "\n",
    "For relatively small `N` values, the performance overhead of overhead of Ray is a larger percentage of the calculation, so the overall performance benefit is less. However, as `N` increases, the advantage of Ray increases. Both plots are roughly-linear, because we are CPU bound, but Ray's execution time/N is lower. On a full cluster, the times could be dramatically better for larger `N`. \n",
    "\n",
    "A log-log plot shows the lower-N behavior more clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_lines = two_lines_plot(\n",
    "    \"N vs. Execution Times (Smaller Is Better)\", 'N', 'Time', 'No Ray', 'Ray', \n",
    "    np_data_ns[:,1], np_data_ns[:,2], np_ray_data_ns[:,1], np_ray_data_ns[:,2])\n",
    "show(two_lines, plot_width=800, plot_height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../images/Pi-Ns-vs-times.png).)\n",
    "\n",
    "What about execution times as a function of the number of trials, for a fixed `N`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_lines = two_lines_plot(\n",
    "    \"Trials (N=10,000,000) vs. Execution Times (Smaller Is Better)\", 'Trials', 'Time', 'No Ray', 'Ray', \n",
    "    np_data_trials[:,0], np_data_trials[:,2], np_ray_data_trials[:,0], np_ray_data_trials[:,2], \n",
    "    x_axis_type='linear', y_axis_type='linear')\n",
    "show(two_lines, plot_width=800, plot_height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../images/Pi-trials-vs-times.png).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the approximate mean values and the standard deviations over the `num_workers` trials for each `N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_without_ray_plot = means_stddevs_plot(\n",
    "  np_data_ns[:,1], np_data_ns[:,3], np_data_ns[:,4], title = 'Ï Results without Ray')\n",
    "# Use a grid to make it layout better.\n",
    "pi_without_ray_grid = gridplot([[pi_without_ray_plot]], plot_width=1000, plot_height=400)\n",
    "show(pi_without_ray_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../images/Pi-Results-without-Ray.png).)\n",
    "You may have to use the \"crossed-arrows\" controls scroll horizontally (click and drag) to see all of the graph.\n",
    "\n",
    "As you might expect, for low `N` values, the error bars are large and the mean estimate is poor, but for higher `N`, the errors grow smaller and results converge to the correct value.\n",
    "\n",
    "With Ray, the plot will look similar, because we did the same calculation, just faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_with_ray_plot = means_stddevs_plot(\n",
    "  np_ray_data_ns[:,1], np_ray_data_ns[:,3], np_ray_data_ns[:,4], title = 'Ï Results with Ray')\n",
    "# Use a grid to make it layout better.\n",
    "pi_with_ray_grid = gridplot([[pi_with_ray_plot]], plot_width=1000, plot_height=400)\n",
    "show(pi_with_ray_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../images/Pi-Results-with-Ray.png).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.get() vs. ray.wait()\n",
    "\n",
    "Calling `ray.get(ids)` blocks until all the tasks have completed that correspond to the input `ids`. That has been fine for this tutorial so far, but what if you're waiting for a number of tasks, where some will finish more quickly than others? What if you would like to process the completed results as they become available, even while other tasks are still running? That's where `ray.wait()` is recommended. Here we'll provide a brief example. For more details, see the Advanced Ray, [Ray Tasks Revisited](../advanced-ray/01-Ray-Tasks-Revisited.ipynb) lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_estimate_pi2(n, trial):\n",
    "    time.sleep(trial)\n",
    "    return n, trial, estimate_pi(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_try_it2(ns, trials):\n",
    "    start = time.time()\n",
    "    refs = [ray_estimate_pi2.remote(n, trial) for trial in trials for n in ns]\n",
    "    still_running = list(refs)\n",
    "    while len(still_running) > 0:\n",
    "        finished, still_running = ray.wait(still_running)\n",
    "        ns_trials_pis = ray.get(finished)   # won't block\n",
    "        print(f'{ns_trials_pis}, elapsed time = {time.time() - start} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe what happens next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_try_it2([100000,1000000,1000000], [2,4,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try one or more of the following exercises to practice improving scalable performance using Ray. In particular, think about the granularity of tasks where Ray is most beneficial.\n",
    "\n",
    "See the [solutions notebook](solutions/Ray-Crash-Course-Solutions.ipynb) for a discussion of solutions to these exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "As currently written, the memory footprint of `estimate_pi` scales linearly with `N`, because it allocates two NumPy arrays of size `N`. This limits the size of `N` we can evaluate (as I confirmed by locking up my laptop...). However, this isn't actually necessary. We could do the same calculation in \"blocks, for example `m` blocks of size `N/m` and then combine the results. Furthermore, there's no dependencies between the calculations with those blocks, giving us further potential speed-up by parellelizing them with Ray.\n",
    "\n",
    "Adapt `ray_estimate_pi` to use this technique. Pick some `N` value above which the calculation is done in blocks. Compare the performance of the old vs. new implementation. \n",
    "\n",
    "As you do this exercise, you might ponder the fact that we often averaged multiple trials for a given `N` and then ask yourself, what's the difference between averaging `10` trials for `N = 1000` vs. `1` trial for `N = 10000`, for example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "What `N` value is needed to get a reliable estimate to five decimal places, `3.1415` (for some definition of \"reliable\")? If you have a powerful machine or a cluster, you could try a higher accuracy. You'll need to use the solution to Exercise 1 or you can make a guess based on the results we've already seen in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "For small computation problems, Ray adds enough overhead that its benefits are outweighed. You can see from the performance graphs above that smaller `N` or smaller trial values will likely cause the curves to cross. Try small values of `N` and small trial numbers. When do the lines cross? Try timing individual runs for small `N` around the crossing point. What can you infer from this \"tipping point\" about appropriate sizing of tasks, at least for your test environment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell when you are finished with this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()  # \"Undo ray.init()\". Terminate all the processes started in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next lesson, [Ray Actors](02-Ray-Actors.ipynb), introduces Ray's tool for distributed computation _with state_, **actors**, which builds on the familiar Python concept of classes.               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
